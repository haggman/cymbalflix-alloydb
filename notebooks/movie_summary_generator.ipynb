{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sk0wAONSQSRH"
      },
      "source": [
        "# Movie Summary Generation with Gemini API\n",
        "\n",
        "## Overview\n",
        "This notebook generates AI-powered movie summaries for the MovieLens dataset using Google's Gemini 2.5 Flash via the new **google-genai** SDK with **parallel batch processing**.\n",
        "\n",
        "‚ö†Ô∏è **IMPORTANT:** If you're updating from an older version of this notebook, please **restart the runtime** before running:\n",
        "- Click: **Runtime ‚Üí Restart runtime**\n",
        "- Then run all cells from the beginning\n",
        "\n",
        "**Features:**\n",
        "- Test mode (25 movies) and Full mode (~9,700 movies)\n",
        "- **Parallel processing** with 50 concurrent workers\n",
        "- **Batch processing** for optimal throughput\n",
        "- Progress saving every 100 movies\n",
        "- Automatic retry logic for API failures\n",
        "- Clean CSV output ready for database import\n",
        "- Comprehensive error logging with inline error details\n",
        "\n",
        "**Performance:**\n",
        "- ~50x faster with parallel processing\n",
        "- Full dataset: **15-30 minutes** (vs 5-8 hours sequential)\n",
        "- ~300-600 movies per minute throughput\n",
        "- No grounding needed (movies are in training data)\n",
        "\n",
        "**Requirements:**\n",
        "- Colab Enterprise environment\n",
        "- Vertex AI API enabled in your GCP project\n",
        "- Proper IAM permissions (Vertex AI User role)\n",
        "\n",
        "**SDK:** Uses the new unified `google-genai` SDK (released late 2024)\n",
        "\n",
        "**Output Format:** `summaries.csv` with columns: `movieId,summary`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4qL7DrRQSRJ"
      },
      "source": [
        "## Setup and Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DmMt5YijQSRJ"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "# Using google-genai - the new unified SDK for Gemini API\n",
        "!pip install -q google-genai pandas tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "M_jSD3JwQSRK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "import re\n",
        "import csv\n",
        "from pathlib import Path\n",
        "from tqdm.notebook import tqdm\n",
        "from datetime import datetime\n",
        "from typing import Optional, Tuple\n",
        "import os\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import threading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zXS_wOTfQzVI"
      },
      "outputs": [],
      "source": [
        "import threading\n",
        "_thread_local = threading.local()\n",
        "\n",
        "def get_client():\n",
        "    if getattr(_thread_local, \"client\", None) is None:\n",
        "        from google import genai\n",
        "        import google.auth\n",
        "        credentials, project_id = google.auth.default()\n",
        "        _thread_local.client = genai.Client(\n",
        "            vertexai=True,\n",
        "            project=project_id,\n",
        "            location='us-central1',\n",
        "        )\n",
        "    return _thread_local.client\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykvddLRlQSRK",
        "outputId": "d9fbac3a-212e-4225-8f77-5b0d4317649d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration:\n",
            "  Mode: FULL\n",
            "  Model: gemini-2.5-flash\n",
            "  Movies to process: ALL (~9,700)\n",
            "  Max workers: 50\n",
            "  Save interval: 100 movies\n"
          ]
        }
      ],
      "source": [
        "# Configuration\n",
        "class Config:\n",
        "    \"\"\"Central configuration for the movie summary generator\"\"\"\n",
        "\n",
        "    # Mode: 'test' for 25 movies, 'full' for all movies\n",
        "    MODE = 'full'  # Change to 'full' for production run\n",
        "    DEBUG = True   # Set to True to see detailed error messages\n",
        "\n",
        "    # Data URLs and paths\n",
        "    INPUT_URL = 'https://raw.githubusercontent.com/haggman/cymbalflix/main/starter/data/ml-latest-small/movies.csv'\n",
        "    OUTPUT_FILE = 'summaries.csv'\n",
        "    PROGRESS_FILE = 'summary_progress.csv'\n",
        "    ERROR_LOG = 'summary_errors.csv'\n",
        "\n",
        "    # API Configuration\n",
        "    MODEL_NAME = 'gemini-2.5-flash'  # Latest fast model\n",
        "\n",
        "    # Processing settings\n",
        "    TEST_MODE_LIMIT = 25\n",
        "    SAVE_INTERVAL = 100  # Save progress every N movies\n",
        "    MAX_RETRIES = 3\n",
        "    RETRY_DELAY = 2  # seconds\n",
        "\n",
        "    # Batch processing for speed\n",
        "    BATCH_SIZE = 100  # Process this many movies concurrently\n",
        "    MAX_WORKERS = 50  # Number of parallel threads\n",
        "\n",
        "    # Summary requirements\n",
        "    MIN_SUMMARY_LENGTH = 50  # characters\n",
        "    MAX_SUMMARY_LENGTH = 3000  # characters\n",
        "\n",
        "# Display current configuration\n",
        "print(f\"Configuration:\")\n",
        "print(f\"  Mode: {Config.MODE.upper()}\")\n",
        "print(f\"  Model: {Config.MODEL_NAME}\")\n",
        "print(f\"  Movies to process: {Config.TEST_MODE_LIMIT if Config.MODE == 'test' else 'ALL (~9,700)'}\")\n",
        "print(f\"  Max workers: {Config.MAX_WORKERS}\")\n",
        "print(f\"  Save interval: {Config.SAVE_INTERVAL} movies\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRoUq05fQSRK"
      },
      "source": [
        "## Google GenAI SDK Setup\n",
        "\n",
        "**Note:** Using the new unified `google-genai` SDK. In Colab Enterprise, authentication is automatic via your project's default credentials.\n",
        "\n",
        "**Performance:** Grounding is disabled for speed since these movies (pre-2019) are already in Gemini's training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tW1ZAHx1QSRK",
        "outputId": "0065c1df-b8e7-4cfe-8bc1-046957484b93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Authentication successful\n",
            "   Project: qwiklabs-gcp-01-5c40e6907a04\n",
            "   Location: us-central1\n",
            "   Using Vertex AI: True\n",
            "\n",
            "‚úÖ Ready to use model: gemini-2.5-flash\n"
          ]
        }
      ],
      "source": [
        "# Initialize Google GenAI client for Vertex AI\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "# Get project from environment\n",
        "try:\n",
        "    import google.auth\n",
        "\n",
        "    credentials, project_id = google.auth.default()\n",
        "\n",
        "    print(f\"‚úÖ Authentication successful\")\n",
        "    print(f\"   Project: {project_id}\")\n",
        "    print(f\"   Location: us-central1\")\n",
        "    print(f\"   Using Vertex AI: True\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Authentication error: {e}\")\n",
        "    print(\"Please ensure you're running in Colab Enterprise with proper permissions\")\n",
        "    raise\n",
        "\n",
        "print(f\"\\n‚úÖ Ready to use model: {Config.MODEL_NAME}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5gb-ZxxQSRL"
      },
      "source": [
        "## Summary Generation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqraWS0UQSRL",
        "outputId": "aa60ffd3-ee97-490a-b1ab-382161c035d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Summary generation functions defined\n"
          ]
        }
      ],
      "source": [
        "def create_summary_prompt(title: str, year: Optional[int]) -> str:\n",
        "    # Convert pandas NA to None for boolean check\n",
        "    if pd.isna(year):\n",
        "        year = None\n",
        "\n",
        "    year_str = f\" ({year})\" if year else \"\"\n",
        "\n",
        "    \"\"\"Create a prompt for Gemini to generate a movie summary.\n",
        "\n",
        "    Args:\n",
        "        title: Clean movie title without year\n",
        "        year: Release year (if known)\n",
        "\n",
        "    Returns:\n",
        "        Formatted prompt string\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = f\"\"\"Write a 1-2 paragraph summary of the movie \"{title}\"{year_str}.\n",
        "\n",
        "Include:\n",
        "- Brief plot overview (spoiler-free)\n",
        "- Notable cast and director\n",
        "- Critical reception and cultural impact\n",
        "\n",
        "Write 150-250 words in a neutral, encyclopedic tone.\"\"\"\n",
        "\n",
        "    return prompt\n",
        "\n",
        "\n",
        "def generate_summary(title: str, year: Optional[int], retries: int = Config.MAX_RETRIES) -> Tuple[Optional[str], Optional[str]]:\n",
        "    \"\"\"Generate a movie summary using Gemini API with retry logic.\n",
        "\n",
        "    Args:\n",
        "        title: Clean movie title\n",
        "        year: Release year\n",
        "        retries: Number of retry attempts\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (summary, error_message). If successful, error_message is None.\n",
        "    \"\"\"\n",
        "    prompt = create_summary_prompt(title, year)\n",
        "\n",
        "    # Configure generation parameters (NO grounding for speed)\n",
        "    generate_config = types.GenerateContentConfig(\n",
        "        temperature=1.3,\n",
        "        tools=[types.Tool(google_search=types.GoogleSearch())],\n",
        "    )\n",
        "\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            response = get_client().models.generate_content(\n",
        "                model=Config.MODEL_NAME,\n",
        "                contents=prompt,\n",
        "                config=generate_config,\n",
        "            )\n",
        "\n",
        "            if Config.DEBUG and Config.MODE == 'test' and attempt == 0:\n",
        "                print(f\"\\n  DEBUG - Movie: {title} ({year})\")\n",
        "                print(f\"  Response type: {type(response)}\")\n",
        "                print(f\"  Has text attr: {hasattr(response, 'text')}\")\n",
        "                if hasattr(response, 'candidates'):\n",
        "                    print(f\"  Candidates: {len(response.candidates) if response.candidates else 0}\")\n",
        "\n",
        "            # Extract text from response\n",
        "            summary = None\n",
        "\n",
        "            if hasattr(response, 'text') and response.text:\n",
        "                summary = response.text\n",
        "                if Config.DEBUG and Config.MODE == 'test' and attempt == 0:\n",
        "                    print(f\"  Got text via response.text: {len(summary)} chars\")\n",
        "            elif hasattr(response, 'candidates') and response.candidates:\n",
        "                candidate = response.candidates[0]\n",
        "                if hasattr(candidate, 'content') and hasattr(candidate.content, 'parts'):\n",
        "                    parts = candidate.content.parts\n",
        "                    if parts and hasattr(parts[0], 'text'):\n",
        "                        summary = parts[0].text\n",
        "                        if Config.DEBUG and Config.MODE == 'test' and attempt == 0:\n",
        "                            print(f\"  Got text via candidates: {len(summary)} chars\")\n",
        "\n",
        "            # Check if we got valid text\n",
        "            if not summary:\n",
        "                if Config.DEBUG and Config.MODE == 'test':\n",
        "                    print(f\"  No summary extracted on attempt {attempt + 1}\")\n",
        "                if attempt < retries - 1:\n",
        "                    time.sleep(Config.RETRY_DELAY)\n",
        "                    continue\n",
        "                return None, \"No summary text in API response\"\n",
        "\n",
        "            summary = summary.strip()\n",
        "\n",
        "            # Validate summary quality\n",
        "            if not summary or len(summary) < Config.MIN_SUMMARY_LENGTH:\n",
        "                if attempt < retries - 1:\n",
        "                    time.sleep(Config.RETRY_DELAY)\n",
        "                    continue\n",
        "                return None, f\"Summary too short ({len(summary)} chars)\"\n",
        "\n",
        "            if len(summary) > Config.MAX_SUMMARY_LENGTH:\n",
        "                summary = summary[:Config.MAX_SUMMARY_LENGTH] + \"...\"\n",
        "\n",
        "            return summary, None\n",
        "\n",
        "        except AttributeError as e:\n",
        "            error_msg = f\"AttributeError: {str(e)}\"\n",
        "            if Config.DEBUG and Config.MODE == 'test':\n",
        "                print(f\"  {error_msg} on attempt {attempt + 1}\")\n",
        "            if attempt < retries - 1:\n",
        "                time.sleep(Config.RETRY_DELAY * (attempt + 1))\n",
        "                continue\n",
        "            return None, error_msg\n",
        "        except Exception as e:\n",
        "            error_msg = f\"{type(e).__name__}: {str(e)}\"\n",
        "            if Config.DEBUG and Config.MODE == 'test':\n",
        "                print(f\"  {error_msg} on attempt {attempt + 1}\")\n",
        "            if attempt < retries - 1:\n",
        "                time.sleep(Config.RETRY_DELAY * (attempt + 1))\n",
        "                continue\n",
        "            return None, error_msg\n",
        "\n",
        "    return None, \"Max retries exceeded\"\n",
        "\n",
        "\n",
        "def clean_summary_for_csv(summary: str) -> str:\n",
        "    \"\"\"Clean summary text for CSV output following MovieLens format.\n",
        "\n",
        "    Args:\n",
        "        summary: Raw summary text\n",
        "\n",
        "    Returns:\n",
        "        Cleaned summary suitable for CSV (double-quote escaped, UTF-8)\n",
        "    \"\"\"\n",
        "    if not summary:\n",
        "        return \"\"\n",
        "\n",
        "    # Remove excessive whitespace\n",
        "    summary = re.sub(r'\\s+', ' ', summary)\n",
        "\n",
        "    # CSV standard: escape double quotes by doubling them\n",
        "    summary = summary.replace('\"', '\"\"')\n",
        "\n",
        "    return summary.strip()\n",
        "\n",
        "print(\"‚úÖ Summary generation functions defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDoI13K6QSRK"
      },
      "source": [
        "## Test API Connection\n",
        "\n",
        "Quick test to verify the API is working correctly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGZo7PwbQSRK",
        "outputId": "8f9c43fd-0048-46ec-c31c-99681be8c512"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ API Test Successful!\n",
            "Response type: <class 'google.genai.types.GenerateContentResponse'>\n",
            "Has text attribute: True\n",
            "Text is None: False\n",
            "Sample text: When a new, high-tech action figure named Buzz Lightyear threatens his status, a pull-string cowboy \n",
            "\n",
            "============================================================\n",
            "Testing summary generation...\n",
            "============================================================\n",
            "\n",
            "‚úÖ Summary generation working!\n",
            "Length: 1589 characters\n",
            "Preview: \"Toy Story\" (1995), directed by John Lasseter, is a pioneering animated film that introduced audiences to a world where toys come to life when humans are absent. The plot centers on Woody (voiced by T...\n"
          ]
        }
      ],
      "source": [
        "# Test with a simple movie to verify API response format\n",
        "try:\n",
        "    test_config = types.GenerateContentConfig(\n",
        "        temperature=0.7,\n",
        "        max_output_tokens=200,\n",
        "    )\n",
        "\n",
        "    test_response = get_client().models.generate_content(\n",
        "        model=Config.MODEL_NAME,\n",
        "        contents='Write one sentence about the movie Toy Story.',\n",
        "        config=test_config,\n",
        "    )\n",
        "\n",
        "    print(\"‚úÖ API Test Successful!\")\n",
        "    print(f\"Response type: {type(test_response)}\")\n",
        "    print(f\"Has text attribute: {hasattr(test_response, 'text')}\")\n",
        "\n",
        "    if hasattr(test_response, 'text'):\n",
        "        print(f\"Text is None: {test_response.text is None}\")\n",
        "        if test_response.text:\n",
        "            print(f\"Sample text: {test_response.text[:100]}\")\n",
        "    else:\n",
        "        print(f\"Response object: {test_response}\")\n",
        "        print(f\"Response dir: {[attr for attr in dir(test_response) if not attr.startswith('_')]}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå API Test Failed: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "# Test generating a movie summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Testing summary generation...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "test_summary, test_error = generate_summary(\"Toy Story\", 1995)\n",
        "if test_summary:\n",
        "    print(f\"\\n‚úÖ Summary generation working!\")\n",
        "    print(f\"Length: {len(test_summary)} characters\")\n",
        "    print(f\"Preview: {test_summary[:200]}...\")\n",
        "else:\n",
        "    print(f\"\\n‚ùå Summary generation failed: {test_error}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJLqOFjDQSRL"
      },
      "source": [
        "## Load and Prepare Movie Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQY49p9DQSRL",
        "outputId": "0e09fae4-b257-47d7-9e57-adbb4976e09e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading movie data from: https://raw.githubusercontent.com/haggman/cymbalflix/main/starter/data/ml-latest-small/movies.csv\n",
            "\n",
            "‚úÖ FULL MODE: Processing all 9742 movies\n",
            "\n",
            "Dataset info:\n",
            "  Total movies: 9742\n",
            "  Movies with years: 9729\n",
            "  Year range: 1902 - 2018\n",
            "\n",
            "Sample movies:\n",
            "   movieId                               title                  clean_title  \\\n",
            "0        1                    Toy Story (1995)                    Toy Story   \n",
            "1        2                      Jumanji (1995)                      Jumanji   \n",
            "2        3             Grumpier Old Men (1995)             Grumpier Old Men   \n",
            "3        4            Waiting to Exhale (1995)            Waiting to Exhale   \n",
            "4        5  Father of the Bride Part II (1995)  Father of the Bride Part II   \n",
            "\n",
            "   year                                       genres  \n",
            "0  1995  Adventure|Animation|Children|Comedy|Fantasy  \n",
            "1  1995                   Adventure|Children|Fantasy  \n",
            "2  1995                               Comedy|Romance  \n",
            "3  1995                         Comedy|Drama|Romance  \n",
            "4  1995                                       Comedy  \n"
          ]
        }
      ],
      "source": [
        "def extract_year_from_title(title: str) -> Tuple[str, Optional[int]]:\n",
        "    \"\"\"Extract year from movie title.\n",
        "\n",
        "    Args:\n",
        "        title: Movie title potentially containing year in format \"Title (YYYY)\"\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (clean_title, year)\n",
        "    \"\"\"\n",
        "    # Match year in parentheses at end of title\n",
        "    match = re.search(r'\\((\\d{4})\\)\\s*$', title)\n",
        "\n",
        "    if match:\n",
        "        year = int(match.group(1))\n",
        "        clean_title = title[:match.start()].strip()\n",
        "        return clean_title, year\n",
        "\n",
        "    return title.strip(), None\n",
        "\n",
        "\n",
        "# Load movie data\n",
        "print(f\"Loading movie data from: {Config.INPUT_URL}\")\n",
        "df = pd.read_csv(Config.INPUT_URL)\n",
        "\n",
        "# Apply mode limit\n",
        "if Config.MODE == 'test':\n",
        "    df = df.head(Config.TEST_MODE_LIMIT)\n",
        "    print(f\"\\n‚ö†Ô∏è  TEST MODE: Processing first {Config.TEST_MODE_LIMIT} movies only\")\n",
        "else:\n",
        "    print(f\"\\n‚úÖ FULL MODE: Processing all {len(df)} movies\")\n",
        "\n",
        "# Extract years from titles\n",
        "df[['clean_title', 'year']] = df['title'].apply(\n",
        "    lambda x: pd.Series(extract_year_from_title(x))\n",
        ")\n",
        "\n",
        "# Convert year to nullable integer type (keeps integers, allows None)\n",
        "df['year'] = df['year'].astype('Int64')  # Capital I - nullable integer dtype\n",
        "\n",
        "\n",
        "# Validate years (should be reasonable movie years)\n",
        "valid_years = df['year'].notna() & (df['year'] >= 1888) & (df['year'] <= 2030)\n",
        "invalid_year_count = (~valid_years & df['year'].notna()).sum()\n",
        "if invalid_year_count > 0:\n",
        "    print(f\"\\n‚ö†Ô∏è  Warning: Found {invalid_year_count} movies with invalid years, setting to None\")\n",
        "    df.loc[~valid_years, 'year'] = None\n",
        "\n",
        "print(f\"\\nDataset info:\")\n",
        "print(f\"  Total movies: {len(df)}\")\n",
        "print(f\"  Movies with years: {df['year'].notna().sum()}\")\n",
        "if df['year'].notna().sum() > 0:\n",
        "    print(f\"  Year range: {df['year'].min():.0f} - {df['year'].max():.0f}\")\n",
        "\n",
        "# Display sample\n",
        "print(f\"\\nSample movies:\")\n",
        "print(df[['movieId', 'title', 'clean_title', 'year', 'genres']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mV9xWSWQSRL"
      },
      "source": [
        "## Progress Tracking Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6plqPhu3QSRL",
        "outputId": "c2510134-26a2-4a7a-e410-53bf3f728f82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Progress tracking functions defined\n"
          ]
        }
      ],
      "source": [
        "def save_progress(df_processed: pd.DataFrame, filename: str = Config.PROGRESS_FILE):\n",
        "    \"\"\"Save processed summaries to CSV.\n",
        "\n",
        "    Args:\n",
        "        df_processed: DataFrame with movieId and summary columns\n",
        "        filename: Output filename\n",
        "    \"\"\"\n",
        "    # Select only the required columns: movieId and summary\n",
        "    output_cols = ['movieId', 'summary']\n",
        "    df_output = df_processed[output_cols].copy()\n",
        "\n",
        "    # Save to CSV with UTF-8 encoding and proper quoting for MovieLens format\n",
        "    df_output.to_csv(filename, index=False, encoding='utf-8', quoting=csv.QUOTE_MINIMAL)\n",
        "    print(f\"  üíæ Progress saved: {filename} ({len(df_output)} movies)\")\n",
        "\n",
        "\n",
        "def log_error(movie_id: int, title: str, error_msg: str, filename: str = Config.ERROR_LOG):\n",
        "    \"\"\"Log errors to CSV file.\n",
        "\n",
        "    Args:\n",
        "        movie_id: Movie ID\n",
        "        title: Movie title\n",
        "        error_msg: Error message\n",
        "        filename: Error log filename\n",
        "    \"\"\"\n",
        "    error_data = {\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'movieId': movie_id,\n",
        "        'title': title,\n",
        "        'error': error_msg\n",
        "    }\n",
        "\n",
        "    file_exists = Path(filename).exists()\n",
        "\n",
        "    with open(filename, 'a', newline='', encoding='utf-8') as f:\n",
        "        writer = csv.DictWriter(f, fieldnames=['timestamp', 'movieId', 'title', 'error'])\n",
        "        if not file_exists:\n",
        "            writer.writeheader()\n",
        "        writer.writerow(error_data)\n",
        "\n",
        "print(\"‚úÖ Progress tracking functions defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9RuBIoNQSRL"
      },
      "source": [
        "## Parallel Batch Processing\n",
        "\n",
        "**Speed optimization:** Processes movies in batches with multiple concurrent workers for ~50x faster throughput."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_76YRm5dQSRM",
        "outputId": "9a532788-7697-4c5f-d430-550eb43eb52c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Parallel processing functions defined\n"
          ]
        }
      ],
      "source": [
        "def process_single_movie(row: pd.Series) -> dict:\n",
        "    \"\"\"Process a single movie (called by worker threads).\n",
        "\n",
        "    Args:\n",
        "        row: DataFrame row with movie data\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with movie result\n",
        "    \"\"\"\n",
        "    movie_id = row['movieId']\n",
        "    title = row['title']\n",
        "    clean_title = row['clean_title']\n",
        "    year = row['year']\n",
        "\n",
        "    # Print individual movie progress only in test mode\n",
        "    if Config.MODE == 'test':\n",
        "        print(f\"  Processing: {title}\")\n",
        "\n",
        "    # Generate summary\n",
        "    summary, error = generate_summary(clean_title, year)\n",
        "\n",
        "    if summary:\n",
        "        summary_clean = clean_summary_for_csv(summary)\n",
        "        return {\n",
        "            'movieId': movie_id,\n",
        "            'summary': summary_clean,\n",
        "            'error': None\n",
        "        }\n",
        "    else:\n",
        "        # Log error to separate file\n",
        "        log_error(movie_id, title, error)\n",
        "\n",
        "        # Include error details inline in the summary field\n",
        "        error_summary = f\"[Summary generation failed: {error}]\"\n",
        "        return {\n",
        "            'movieId': movie_id,\n",
        "            'summary': error_summary,\n",
        "            'error': error\n",
        "        }\n",
        "\n",
        "\n",
        "def process_movies(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Process all movies with parallel batch processing for speed.\n",
        "\n",
        "    Automatically resumes from progress file if it exists, skipping already-processed movies.\n",
        "\n",
        "    Args:\n",
        "        df: Input DataFrame with movies\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with summaries added\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    errors = []\n",
        "\n",
        "    # Check for existing progress and load it\n",
        "    progress_path = Path(Config.PROGRESS_FILE)\n",
        "    processed_ids = set()\n",
        "\n",
        "    if progress_path.exists():\n",
        "        print(f\"\\nüìÇ Found existing progress file: {Config.PROGRESS_FILE}\")\n",
        "        df_progress = pd.read_csv(Config.PROGRESS_FILE)\n",
        "\n",
        "        # Only skip movies that have successful summaries OR non-error summaries\n",
        "        # Re-process any that have error messages\n",
        "        successful_progress = df_progress[~df_progress['summary'].str.contains(r'\\[Summary generation failed', na=False)]\n",
        "        processed_ids = set(successful_progress['movieId'])\n",
        "\n",
        "        # Keep successful summaries in results\n",
        "        for _, row in successful_progress.iterrows():\n",
        "            results.append({\n",
        "                'movieId': row['movieId'],\n",
        "                'summary': row['summary'],\n",
        "                'error': None\n",
        "            })\n",
        "\n",
        "        # Check for failed summaries to retry\n",
        "        failed_ids = set(df_progress[df_progress['summary'].str.contains(r'\\[Summary generation failed', na=False)]['movieId'])\n",
        "\n",
        "        print(f\"  ‚úÖ Loaded {len(successful_progress)} successful summaries\")\n",
        "        print(f\"  üîÑ Will retry {len(failed_ids)} failed summaries\")\n",
        "        print(f\"  üìù Remaining to process: {len(df) - len(processed_ids)}\")\n",
        "\n",
        "    # Filter to only unprocessed movies\n",
        "    df_to_process = df[~df['movieId'].isin(processed_ids)].copy()\n",
        "\n",
        "    if len(df_to_process) == 0:\n",
        "        print(f\"\\n‚úÖ All movies already processed! Loading final results...\")\n",
        "        df_final = pd.read_csv(Config.PROGRESS_FILE)\n",
        "        return df_final\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Starting PARALLEL summary generation\")\n",
        "    print(f\"  Total movies in dataset: {len(df)}\")\n",
        "    print(f\"  Already processed: {len(processed_ids)}\")\n",
        "    print(f\"  Movies to process: {len(df_to_process)}\")\n",
        "    print(f\"  Batch size: {Config.BATCH_SIZE}\")\n",
        "    print(f\"  Workers: {Config.MAX_WORKERS}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Process in batches with parallel workers\n",
        "    total_batches = (len(df_to_process) + Config.BATCH_SIZE - 1) // Config.BATCH_SIZE\n",
        "\n",
        "    with tqdm(total=len(df_to_process), desc=\"Generating summaries\", disable=(Config.MODE == 'test')) as pbar:\n",
        "        for batch_num in range(total_batches):\n",
        "            start_idx = batch_num * Config.BATCH_SIZE\n",
        "            end_idx = min(start_idx + Config.BATCH_SIZE, len(df_to_process))\n",
        "            batch_df = df_to_process.iloc[start_idx:end_idx]\n",
        "\n",
        "            # Process batch in parallel\n",
        "            with ThreadPoolExecutor(max_workers=Config.MAX_WORKERS) as executor:\n",
        "                # Submit all movies in batch\n",
        "                futures = {\n",
        "                    executor.submit(process_single_movie, row): idx\n",
        "                    for idx, row in batch_df.iterrows()\n",
        "                }\n",
        "\n",
        "                # Collect results as they complete\n",
        "                for future in as_completed(futures):\n",
        "                    result = future.result()\n",
        "                    results.append(result)\n",
        "\n",
        "                    if result['error']:\n",
        "                        errors.append(result['movieId'])\n",
        "\n",
        "                    if Config.MODE != 'test':\n",
        "                        pbar.update(1)\n",
        "\n",
        "            # Save progress after each batch\n",
        "            if len(results) % Config.SAVE_INTERVAL == 0 or end_idx == len(df_to_process):\n",
        "                df_progress = pd.DataFrame(results)\n",
        "                # Remove error column before saving\n",
        "                df_progress = df_progress.drop(columns=['error'])\n",
        "                save_progress(df_progress, Config.PROGRESS_FILE)\n",
        "\n",
        "    # Final save\n",
        "    df_results = pd.DataFrame(results)\n",
        "    df_results = df_results.drop(columns=['error'])\n",
        "    save_progress(df_results, Config.OUTPUT_FILE)\n",
        "\n",
        "    # Summary statistics\n",
        "    elapsed = time.time() - start_time\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Processing Complete!\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"  Total movies in dataset: {len(df)}\")\n",
        "    print(f\"  Newly processed: {len(df_to_process)}\")\n",
        "    print(f\"  Total with summaries: {len(df_results)}\")\n",
        "    print(f\"  Successful: {len(df_results) - len(errors)}\")\n",
        "    print(f\"  Errors: {len(errors)}\")\n",
        "    if len(df_to_process) > 0:\n",
        "        print(f\"  Time elapsed: {elapsed/60:.1f} minutes ({elapsed/3600:.1f} hours)\")\n",
        "        print(f\"  Average time per movie: {elapsed/len(df_to_process):.2f} seconds\")\n",
        "        print(f\"  Effective throughput: {len(df_to_process)/elapsed*60:.1f} movies/minute\")\n",
        "    print(f\"\\n  Output file: {Config.OUTPUT_FILE}\")\n",
        "\n",
        "    if errors:\n",
        "        print(f\"  Error log: {Config.ERROR_LOG}\")\n",
        "        print(f\"  Error rate: {len(errors)/len(df_results)*100:.1f}%\")\n",
        "\n",
        "    return df_results\n",
        "\n",
        "print(\"‚úÖ Parallel processing functions defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Syy5fMaIQSRM"
      },
      "source": [
        "## Run Summary Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZMTsV4KQSRM",
        "outputId": "72bf5536-9cf8-46d8-c440-ca0014f539d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìÇ Found existing progress file: summary_progress.csv\n",
            "  ‚úÖ Loaded 9742 successful summaries\n",
            "  üîÑ Will retry 0 failed summaries\n",
            "  üìù Remaining to process: 0\n",
            "\n",
            "‚úÖ All movies already processed! Loading final results...\n"
          ]
        }
      ],
      "source": [
        "# Run the processing\n",
        "df_with_summaries = process_movies(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37cab1b4",
        "outputId": "c8d0cd68-97b9-4195-d1c2-917060107007"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No failed summary messages found in 'summary_progress.csv'.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:8: SyntaxWarning: invalid escape sequence '\\['\n",
            "<>:8: SyntaxWarning: invalid escape sequence '\\['\n",
            "/tmp/ipython-input-1408209446.py:8: SyntaxWarning: invalid escape sequence '\\['\n",
            "  failed_summaries = df_progress[df_progress['summary'].str.contains('\\[Summary generation failed', na=False)]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the summary_progress.csv file\n",
        "try:\n",
        "    df_progress = pd.read_csv('/content/summary_progress.csv')\n",
        "\n",
        "    # Filter for failed summaries\n",
        "    # Correcting the regex to properly escape the '[' character to avoid SyntaxWarning\n",
        "    failed_summaries = df_progress[df_progress['summary'].str.contains(r'\\[Summary generation failed', na=False)]\n",
        "\n",
        "    if not failed_summaries.empty:\n",
        "        print(f\"Found {len(failed_summaries)} failed summary messages:\")\n",
        "        display(failed_summaries)\n",
        "    else:\n",
        "        print(\"No failed summary messages found in 'summary_progress.csv'.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'summary_progress.csv' not found. Please ensure the file exists.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUDtnVW1QSRM"
      },
      "source": [
        "## Verify Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u66uvpreQSRM",
        "outputId": "76a1b7a5-5cc4-4169-f74f-852fc07042ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Sample Results:\n",
            "\n",
            "================================================================================\n",
            "\n",
            "Movie #1:\n",
            "  ID: 24\n",
            "  Summary: The 1995 science fiction drama \"\"Powder,\"\" directed and written by Victor Salva, tells the story of Jeremy \"\"Powder\"\" Reed, an albino teenager with extraordinary intellect and unique telepathic and ps...\n",
            "  Summary length: 1587 characters\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Movie #2:\n",
            "  ID: 6\n",
            "  Summary: Michael Mann's 1995 crime drama, \"\"Heat,\"\" meticulously chronicles the high-stakes cat-and-mouse game between a seasoned crew of professional thieves and a determined unit of LAPD robbery-homicide det...\n",
            "  Summary length: 1370 characters\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Movie #3:\n",
            "  ID: 1\n",
            "  Summary: \"\"Toy Story,\"\" released in 1995, is an American animated adventure comedy film produced by Pixar Animation Studios and distributed by Walt Disney Pictures. It tells the story of a group of toys who co...\n",
            "  Summary length: 1713 characters\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Display sample results\n",
        "print(\"\\nüìä Sample Results:\\n\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for idx in range(min(3, len(df_with_summaries))):\n",
        "    row = df_with_summaries.iloc[idx]\n",
        "    print(f\"\\nMovie #{idx+1}:\")\n",
        "    print(f\"  ID: {row['movieId']}\")\n",
        "    print(f\"  Summary: {row['summary'][:200]}...\")\n",
        "    print(f\"  Summary length: {len(row['summary'])} characters\")\n",
        "    print(\"-\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKAX1cS-QSRM",
        "outputId": "568f6dee-2333-4f3e-e23e-9fb967474533"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîç Quality Checks:\n",
            "\n",
            "  Missing summaries: 0\n",
            "  Failed summaries: 0\n",
            "\n",
            "  Summary length statistics:\n",
            "    Min: 673 characters\n",
            "    Max: 3014 characters\n",
            "    Mean: 1484 characters\n",
            "    Median: 1477 characters\n",
            "\n",
            "  Summaries in target range (150-250 chars): 9332 (95.8%)\n",
            "\n",
            "  Completeness check:\n",
            "    Original movies: 9742\n",
            "    Movies with summaries: 9742\n",
            "    Missing summaries: 0\n",
            "    Extra summaries: 0\n",
            "    ‚úÖ Perfect match! All movies have summaries.\n"
          ]
        }
      ],
      "source": [
        "# Quality checks\n",
        "print(\"\\nüîç Quality Checks:\\n\")\n",
        "\n",
        "# Check for missing summaries\n",
        "missing = df_with_summaries['summary'].isna().sum()\n",
        "failed = df_with_summaries['summary'].str.contains(r'\\[Summary generation failed', na=False).sum()\n",
        "print(f\"  Missing summaries: {missing}\")\n",
        "print(f\"  Failed summaries: {failed}\")\n",
        "\n",
        "# Summary length distribution\n",
        "df_with_summaries['summary_length'] = df_with_summaries['summary'].str.len()\n",
        "print(f\"\\n  Summary length statistics:\")\n",
        "print(f\"    Min: {df_with_summaries['summary_length'].min()} characters\")\n",
        "print(f\"    Max: {df_with_summaries['summary_length'].max()} characters\")\n",
        "print(f\"    Mean: {df_with_summaries['summary_length'].mean():.0f} characters\")\n",
        "print(f\"    Median: {df_with_summaries['summary_length'].median():.0f} characters\")\n",
        "\n",
        "# Check for summaries within target range (excluding failures)\n",
        "successful_summaries = df_with_summaries[~df_with_summaries['summary'].str.contains(r'\\[Summary generation failed', na=False)]\n",
        "in_range = successful_summaries[\n",
        "    (successful_summaries['summary_length'] >= 900) &\n",
        "    (successful_summaries['summary_length'] <= 1800)\n",
        "]\n",
        "if len(successful_summaries) > 0:\n",
        "    print(f\"\\n  Summaries in target range (150-250 chars): {len(in_range)} ({len(in_range)/len(successful_summaries)*100:.1f}%)\")\n",
        "\n",
        "# Check for completeness - every movie should have a summary\n",
        "print(f\"\\n  Completeness check:\")\n",
        "original_movie_ids = set(df['movieId'])\n",
        "summary_movie_ids = set(df_with_summaries['movieId'])\n",
        "\n",
        "missing_summaries = original_movie_ids - summary_movie_ids\n",
        "extra_summaries = summary_movie_ids - original_movie_ids\n",
        "\n",
        "print(f\"    Original movies: {len(original_movie_ids)}\")\n",
        "print(f\"    Movies with summaries: {len(summary_movie_ids)}\")\n",
        "print(f\"    Missing summaries: {len(missing_summaries)}\")\n",
        "print(f\"    Extra summaries: {len(extra_summaries)}\")\n",
        "\n",
        "if len(missing_summaries) == 0 and len(extra_summaries) == 0:\n",
        "    print(f\"    ‚úÖ Perfect match! All movies have summaries.\")\n",
        "elif len(missing_summaries) > 0:\n",
        "    print(f\"    ‚ö†Ô∏è  Missing summaries for movie IDs: {sorted(list(missing_summaries))[:10]}{'...' if len(missing_summaries) > 10 else ''}\")\n",
        "if len(extra_summaries) > 0:\n",
        "    print(f\"    ‚ö†Ô∏è  Extra summaries for movie IDs: {sorted(list(extra_summaries))[:10]}{'...' if len(extra_summaries) > 10 else ''}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jg45KbwtQSRM"
      },
      "source": [
        "## Download Results\n",
        "\n",
        "Your results are saved to `summaries.csv`. You can download it from the files panel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2b-FadrQSRM",
        "outputId": "cc4772d0-5d35-42ba-ae06-7f9f621abd72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚úÖ Output file ready for download:\n",
            "  Filename: summaries.csv\n",
            "  Size: 14309.9 KB\n",
            "  Records: 9742\n",
            "  Format: movieId,summary\n",
            "\n",
            "  Download from the files panel on the left ‚Üí\n"
          ]
        }
      ],
      "source": [
        "# Display final file info\n",
        "from pathlib import Path\n",
        "\n",
        "output_path = Path(Config.OUTPUT_FILE)\n",
        "if output_path.exists():\n",
        "    file_size = output_path.stat().st_size / 1024  # KB\n",
        "    print(f\"\\n‚úÖ Output file ready for download:\")\n",
        "    print(f\"  Filename: {Config.OUTPUT_FILE}\")\n",
        "    print(f\"  Size: {file_size:.1f} KB\")\n",
        "    print(f\"  Records: {len(df_with_summaries)}\")\n",
        "    print(f\"  Format: movieId,summary\")\n",
        "    print(f\"\\n  Download from the files panel on the left ‚Üí\")\n",
        "else:\n",
        "    print(f\"‚ùå Output file not found: {Config.OUTPUT_FILE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GV8RRrRLQSRM"
      },
      "source": [
        "## Resume Processing\n",
        "\n",
        "**Good news!** The notebook now automatically resumes from where it left off.\n",
        "\n",
        "- If processing is interrupted, simply re-run the \"Run Summary Generation\" cell\n",
        "- Already-processed successful summaries will be loaded automatically\n",
        "- Only failed summaries and unprocessed movies will be regenerated\n",
        "- Progress is saved every 100 movies to minimize data loss\n",
        "\n",
        "The resume logic:\n",
        "- ‚úÖ Skips movies with successful summaries\n",
        "- üîÑ Retries movies that previously failed\n",
        "- üìù Processes any remaining movies\n",
        "\n",
        "To start completely fresh, delete these files:\n",
        "- `summary_progress.csv`\n",
        "- `summaries.csv`\n",
        "- `summary_errors.csv`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bf7g4PASQSRM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmzo5y0XQSRM"
      },
      "source": [
        "## Troubleshooting\n",
        "\n",
        "### Common Issues\n",
        "\n",
        "**403 Authentication Error:**\n",
        "- Ensure Vertex AI API is enabled in your GCP project\n",
        "- Verify you have the 'Vertex AI User' IAM role\n",
        "- Check that you're running in Colab Enterprise (not regular Colab)\n",
        "\n",
        "**Rate Limiting:**\n",
        "- Reduce `Config.MAX_WORKERS` (try 25 or 10)\n",
        "- Increase `Config.RETRY_DELAY` to slow down retries\n",
        "\n",
        "**API Quota Exceeded:**\n",
        "- Check your Vertex AI quotas in GCP Console\n",
        "- Reduce `Config.MAX_WORKERS` to lower concurrent requests\n",
        "- Run in test mode first to verify everything works\n",
        "\n",
        "**To Enable Vertex AI:**\n",
        "```bash\n",
        "gcloud services enable aiplatform.googleapis.com\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Movie Embeddings for Vector Search\n",
        "\n",
        "Now that we have summaries, let's generate embeddings (numerical vector representations) for each movie. These embeddings will power semantic similarity search - finding movies that are conceptually similar even if they don't share keywords.\n",
        "\n",
        "**Features:**\n",
        "- Uses Gemini Embedding model (gemini-embedding-001)\n",
        "- Output dimension: 1536\n",
        "- Parallel processing with 50 workers\n",
        "- Combines title, genres, and summary for rich context\n",
        "- Output: embeddings.csv (movieId, embedding)"
      ],
      "metadata": {
        "id": "1YwBO2t-upMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding generation configuration\n",
        "class EmbeddingConfig:\n",
        "    \"\"\"Configuration for embedding generation\"\"\"\n",
        "\n",
        "    # Model settings\n",
        "    EMBEDDING_MODEL = 'gemini-embedding-001'\n",
        "    OUTPUT_DIMENSION = 1536\n",
        "\n",
        "    # Input/Output files\n",
        "    SUMMARIES_FILE = 'summaries.csv'\n",
        "    OUTPUT_FILE = 'embeddings.csv'\n",
        "    PROGRESS_FILE = 'embedding_progress.csv'\n",
        "    ERROR_LOG = 'embedding_errors.csv'\n",
        "\n",
        "    # Processing settings\n",
        "    BATCH_SIZE = 100\n",
        "    MAX_WORKERS = 50\n",
        "    SAVE_INTERVAL = 100\n",
        "    MAX_RETRIES = 3\n",
        "    RETRY_DELAY = 2\n",
        "\n",
        "print(\"Embedding generation configuration loaded\")\n",
        "print(f\"  Model: {EmbeddingConfig.EMBEDDING_MODEL}\")\n",
        "print(f\"  Dimensions: {EmbeddingConfig.OUTPUT_DIMENSION}\")\n",
        "print(f\"  Max workers: {EmbeddingConfig.MAX_WORKERS}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKlrXR08urfj",
        "outputId": "46692d1f-c2b8-44e4-a545-0fa2457633ab"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding generation configuration loaded\n",
            "  Model: gemini-embedding-001\n",
            "  Dimensions: 1536\n",
            "  Max workers: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.genai import types\n",
        "\n",
        "print(\"‚úÖ Google GenAI types imported\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04OLGPkg649Y",
        "outputId": "3c4902fc-dfa0-45b1-adc7-416dfe4f222d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Google GenAI types imported\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from typing import Optional, List\n",
        "\n",
        "def create_embedding_text(title: str, genres: List[str], summary: str) -> str:\n",
        "    \"\"\"Create rich text from movie data for embedding.\n",
        "\n",
        "    Args:\n",
        "        title: Movie title\n",
        "        genres: List of genres\n",
        "        summary: Movie summary\n",
        "\n",
        "    Returns:\n",
        "        Combined text optimized for embedding\n",
        "    \"\"\"\n",
        "    genre_text = ', '.join(genres) if genres else ''\n",
        "\n",
        "    parts = [\n",
        "        f\"Title: {title}\",\n",
        "        f\"Genres: {genre_text}\" if genre_text else \"\",\n",
        "        f\"Summary: {summary}\" if summary else \"\"\n",
        "    ]\n",
        "\n",
        "    return '. '.join(filter(None, parts))\n",
        "\n",
        "\n",
        "def generate_embedding(movie_id: int, title: str, genres: List[str], summary: str,\n",
        "                       retries: int = EmbeddingConfig.MAX_RETRIES) -> tuple[Optional[List[float]], Optional[str]]:\n",
        "    \"\"\"Generate embedding for a single movie.\n",
        "\n",
        "    Args:\n",
        "        movie_id: Movie ID\n",
        "        title: Movie title\n",
        "        genres: List of genres\n",
        "        summary: Movie summary\n",
        "        retries: Number of retry attempts\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (embedding_vector, error_message)\n",
        "    \"\"\"\n",
        "    text = create_embedding_text(title, genres, summary)\n",
        "\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            response = get_client().models.embed_content(\n",
        "                model=EmbeddingConfig.EMBEDDING_MODEL,\n",
        "                contents=text,\n",
        "                config=types.EmbedContentConfig(\n",
        "                    output_dimensionality=EmbeddingConfig.OUTPUT_DIMENSION\n",
        "                )\n",
        "            )\n",
        "\n",
        "            # Extract embedding values\n",
        "            if hasattr(response, 'embeddings') and response.embeddings:\n",
        "                embedding = response.embeddings[0]\n",
        "                if hasattr(embedding, 'values') and embedding.values:\n",
        "                    return list(embedding.values), None\n",
        "\n",
        "            if attempt < retries - 1:\n",
        "                time.sleep(EmbeddingConfig.RETRY_DELAY)\n",
        "                continue\n",
        "\n",
        "            return None, \"No embedding values in API response\"\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"{type(e).__name__}: {str(e)}\"\n",
        "            if attempt < retries - 1:\n",
        "                time.sleep(EmbeddingConfig.RETRY_DELAY * (attempt + 1))\n",
        "                continue\n",
        "            return None, error_msg\n",
        "\n",
        "    return None, \"Max retries exceeded\"\n",
        "\n",
        "\n",
        "def save_embeddings_progress(df_processed: pd.DataFrame, filename: str = EmbeddingConfig.PROGRESS_FILE):\n",
        "    \"\"\"Save processed embeddings to CSV.\n",
        "\n",
        "    Args:\n",
        "        df_processed: DataFrame with movieId and embedding columns\n",
        "        filename: Output filename\n",
        "    \"\"\"\n",
        "    # Convert embedding arrays to JSON strings for CSV storage\n",
        "    df_output = df_processed.copy()\n",
        "    df_output['embedding'] = df_output['embedding'].apply(json.dumps)\n",
        "\n",
        "    # Save with only required columns\n",
        "    df_output[['movieId', 'embedding']].to_csv(filename, index=False, encoding='utf-8')\n",
        "    print(f\"  üíæ Progress saved: {filename} ({len(df_output)} movies)\")\n",
        "\n",
        "\n",
        "def log_embedding_error(movie_id: int, title: str, error_msg: str,\n",
        "                        filename: str = EmbeddingConfig.ERROR_LOG):\n",
        "    \"\"\"Log embedding generation errors.\n",
        "\n",
        "    Args:\n",
        "        movie_id: Movie ID\n",
        "        title: Movie title\n",
        "        error_msg: Error message\n",
        "        filename: Error log filename\n",
        "    \"\"\"\n",
        "    error_data = {\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'movieId': movie_id,\n",
        "        'title': title,\n",
        "        'error': error_msg\n",
        "    }\n",
        "\n",
        "    file_exists = Path(filename).exists()\n",
        "\n",
        "    with open(filename, 'a', newline='', encoding='utf-8') as f:\n",
        "        writer = csv.DictWriter(f, fieldnames=['timestamp', 'movieId', 'title', 'error'])\n",
        "        if not file_exists:\n",
        "            writer.writeheader()\n",
        "        writer.writerow(error_data)\n",
        "\n",
        "print(\"‚úÖ Embedding generation functions defined\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EP600AcvCtB",
        "outputId": "7d75324a-81ba-40cb-8023-ee5a4d2c00b0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Embedding generation functions defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the movies data (with summaries)\n",
        "print(\"Loading movies data with summaries...\")\n",
        "\n",
        "# Load original movies data from URL to get title and genres\n",
        "MOVIES_URL = 'https://raw.githubusercontent.com/haggman/cymbalflix/main/starter/data/ml-latest-small/movies.csv'\n",
        "df_movies = pd.read_csv(MOVIES_URL)\n",
        "print(f\"‚úì Loaded {len(df_movies)} movies from dataset\")\n",
        "\n",
        "# Parse genres into lists\n",
        "df_movies['genres'] = df_movies['genres'].apply(\n",
        "    lambda x: x.split('|') if x and x != '(no genres listed)' else []\n",
        ")\n",
        "\n",
        "# Read the summaries.csv that's been uploaded to this notebook environment\n",
        "df_summaries = pd.read_csv('summaries.csv')\n",
        "print(f\"‚úì Loaded {len(df_summaries)} movie summaries from uploaded file\")\n",
        "\n",
        "# Merge: summaries + (title and genres from movies dataset)\n",
        "df_movies_with_summaries = df_summaries.merge(\n",
        "    df_movies[['movieId', 'title', 'genres']],\n",
        "    on='movieId',\n",
        "    how='inner'\n",
        ")\n",
        "print(f\"‚úì Merged data: {len(df_movies_with_summaries)} movies with complete information\")\n",
        "\n",
        "# Display sample\n",
        "print(\"\\nSample movie data for embedding:\")\n",
        "sample = df_movies_with_summaries[['movieId', 'title', 'genres', 'summary']].head(3)\n",
        "for _, row in sample.iterrows():\n",
        "    print(f\"\\n  Movie: {row['title']}\")\n",
        "    print(f\"  Genres: {row['genres']}\")\n",
        "    print(f\"  Summary preview: {row['summary'][:100]}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNNR5i6RvKsq",
        "outputId": "80e7299f-661a-43f6-a63f-7bf53a052562"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading movies data with summaries...\n",
            "‚úì Loaded 9742 movies from dataset\n",
            "‚úì Loaded 9742 movie summaries from uploaded file\n",
            "‚úì Merged data: 9742 movies with complete information\n",
            "\n",
            "Sample movie data for embedding:\n",
            "\n",
            "  Movie: Powder (1995)\n",
            "  Genres: ['Drama', 'Sci-Fi']\n",
            "  Summary preview: The 1995 science fiction drama \"Powder,\" directed and written by Victor Salva, tells the story of Je...\n",
            "\n",
            "  Movie: Heat (1995)\n",
            "  Genres: ['Action', 'Crime', 'Thriller']\n",
            "  Summary preview: Michael Mann's 1995 crime drama, \"Heat,\" meticulously chronicles the high-stakes cat-and-mouse game ...\n",
            "\n",
            "  Movie: Toy Story (1995)\n",
            "  Genres: ['Adventure', 'Animation', 'Children', 'Comedy', 'Fantasy']\n",
            "  Summary preview: \"Toy Story,\" released in 1995, is an American animated adventure comedy film produced by Pixar Anima...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test embedding generation with a single movie\n",
        "print(\"Testing embedding generation with a single movie...\\n\")\n",
        "\n",
        "# Get one movie with a summary\n",
        "test_movie = df_movies_with_summaries.iloc[0]\n",
        "print(f\"Test Movie: {test_movie['title']}\")\n",
        "print(f\"Genres: {test_movie['genres']}\")\n",
        "print(f\"Summary preview: {test_movie['summary'][:150]}...\\n\")\n",
        "\n",
        "# Create embedding text\n",
        "test_text = create_embedding_text(\n",
        "    test_movie['title'],\n",
        "    test_movie['genres'],\n",
        "    test_movie['summary']\n",
        ")\n",
        "print(f\"Embedding text (first 200 chars):\\n{test_text[:200]}...\\n\")\n",
        "\n",
        "# Try to generate embedding with explicit dimensions\n",
        "try:\n",
        "    print(f\"Calling Gemini API (requesting {EmbeddingConfig.OUTPUT_DIMENSION} dimensions)...\")\n",
        "    response = get_client().models.embed_content(\n",
        "        model=EmbeddingConfig.EMBEDDING_MODEL,\n",
        "        contents=test_text,\n",
        "        config=types.EmbedContentConfig(\n",
        "            output_dimensionality=EmbeddingConfig.OUTPUT_DIMENSION\n",
        "        )\n",
        "    )\n",
        "\n",
        "    print(\"‚úÖ API call successful!\")\n",
        "    print(f\"Response type: {type(response)}\")\n",
        "    print(f\"Has embeddings attr: {hasattr(response, 'embeddings')}\")\n",
        "\n",
        "    if hasattr(response, 'embeddings') and response.embeddings:\n",
        "        embedding = response.embeddings[0]\n",
        "        print(f\"Embedding type: {type(embedding)}\")\n",
        "        print(f\"Has values attr: {hasattr(embedding, 'values')}\")\n",
        "\n",
        "        if hasattr(embedding, 'values') and embedding.values:\n",
        "            values = list(embedding.values)\n",
        "            print(f\"\\n‚úÖ Successfully generated embedding!\")\n",
        "            print(f\"   Dimensions: {len(values)}\")\n",
        "            print(f\"   Expected: {EmbeddingConfig.OUTPUT_DIMENSION}\")\n",
        "            print(f\"   First 5 values: {values[:5]}\")\n",
        "            print(f\"   Last 5 values: {values[-5:]}\")\n",
        "\n",
        "            if len(values) == EmbeddingConfig.OUTPUT_DIMENSION:\n",
        "                print(f\"\\n‚úÖ Dimension check PASSED!\")\n",
        "            else:\n",
        "                print(f\"\\n‚ö†Ô∏è  Dimension mismatch! Got {len(values)}, expected {EmbeddingConfig.OUTPUT_DIMENSION}\")\n",
        "        else:\n",
        "            print(\"‚ùå No values in embedding\")\n",
        "    else:\n",
        "        print(\"‚ùå No embeddings in response\")\n",
        "        print(f\"Response: {response}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error: {type(e).__name__}: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGighbtG7F8t",
        "outputId": "fd47b70f-e37a-4ebd-8262-fbd6465624df"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing embedding generation with a single movie...\n",
            "\n",
            "Test Movie: Powder (1995)\n",
            "Genres: ['Drama', 'Sci-Fi']\n",
            "Summary preview: The 1995 science fiction drama \"Powder,\" directed and written by Victor Salva, tells the story of Jeremy \"Powder\" Reed, an albino teenager with extrao...\n",
            "\n",
            "Embedding text (first 200 chars):\n",
            "Title: Powder (1995). Genres: Drama, Sci-Fi. Summary: The 1995 science fiction drama \"Powder,\" directed and written by Victor Salva, tells the story of Jeremy \"Powder\" Reed, an albino teenager with ex...\n",
            "\n",
            "Calling Gemini API (requesting 1536 dimensions)...\n",
            "‚úÖ API call successful!\n",
            "Response type: <class 'google.genai.types.EmbedContentResponse'>\n",
            "Has embeddings attr: True\n",
            "Embedding type: <class 'google.genai.types.ContentEmbedding'>\n",
            "Has values attr: True\n",
            "\n",
            "‚úÖ Successfully generated embedding!\n",
            "   Dimensions: 1536\n",
            "   Expected: 1536\n",
            "   First 5 values: [0.006422614213079214, -0.03108868934214115, 0.007843773812055588, -0.05639827623963356, -0.001457727630622685]\n",
            "   Last 5 values: [-0.004730571992695332, 0.021044336259365082, 0.008661065250635147, -0.006161170080304146, -0.013007917441427708]\n",
            "\n",
            "‚úÖ Dimension check PASSED!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_single_movie_embedding(row: pd.Series) -> dict:\n",
        "    \"\"\"Process a single movie to generate embedding.\n",
        "\n",
        "    Args:\n",
        "        row: DataFrame row with movie data\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with movie result\n",
        "    \"\"\"\n",
        "    movie_id = row['movieId']\n",
        "    title = row['title']\n",
        "    genres = row['genres']\n",
        "    summary = row['summary']\n",
        "\n",
        "    # Generate embedding\n",
        "    embedding, error = generate_embedding(movie_id, title, genres, summary)\n",
        "\n",
        "    if embedding:\n",
        "        return {\n",
        "            'movieId': movie_id,\n",
        "            'embedding': embedding,\n",
        "            'error': None\n",
        "        }\n",
        "    else:\n",
        "        # Log error\n",
        "        log_embedding_error(movie_id, title, error)\n",
        "        return {\n",
        "            'movieId': movie_id,\n",
        "            'embedding': None,\n",
        "            'error': error\n",
        "        }\n",
        "\n",
        "\n",
        "def process_movie_embeddings(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Process all movies with parallel embedding generation.\n",
        "\n",
        "    Args:\n",
        "        df: Input DataFrame with movies\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with embeddings added\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    errors = []\n",
        "\n",
        "    # Check for existing progress\n",
        "    progress_path = Path(EmbeddingConfig.PROGRESS_FILE)\n",
        "    processed_ids = set()\n",
        "\n",
        "    if progress_path.exists():\n",
        "        print(f\"\\nüìÇ Found existing progress file: {EmbeddingConfig.PROGRESS_FILE}\")\n",
        "        df_progress = pd.read_csv(EmbeddingConfig.PROGRESS_FILE)\n",
        "\n",
        "        # Parse JSON embeddings and filter out failed ones\n",
        "        df_progress['embedding'] = df_progress['embedding'].apply(\n",
        "            lambda x: json.loads(x) if isinstance(x, str) and x.startswith('[') else None\n",
        "        )\n",
        "        successful_progress = df_progress[df_progress['embedding'].notna()]\n",
        "        processed_ids = set(successful_progress['movieId'])\n",
        "\n",
        "        # Keep successful embeddings in results\n",
        "        for _, row in successful_progress.iterrows():\n",
        "            results.append({\n",
        "                'movieId': row['movieId'],\n",
        "                'embedding': row['embedding'],\n",
        "                'error': None\n",
        "            })\n",
        "\n",
        "        print(f\"  ‚úÖ Loaded {len(successful_progress)} successful embeddings\")\n",
        "        print(f\"  üìù Remaining to process: {len(df) - len(processed_ids)}\")\n",
        "\n",
        "    # Filter to only unprocessed movies\n",
        "    df_to_process = df[~df['movieId'].isin(processed_ids)].copy()\n",
        "\n",
        "    if len(df_to_process) == 0:\n",
        "        print(f\"\\n‚úÖ All movies already processed!\")\n",
        "        # Load and return final results\n",
        "        df_final = pd.read_csv(EmbeddingConfig.PROGRESS_FILE)\n",
        "        df_final['embedding'] = df_final['embedding'].apply(json.loads)\n",
        "        return df_final\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Starting PARALLEL embedding generation\")\n",
        "    print(f\"  Total movies: {len(df)}\")\n",
        "    print(f\"  Already processed: {len(processed_ids)}\")\n",
        "    print(f\"  Movies to process: {len(df_to_process)}\")\n",
        "    print(f\"  Batch size: {EmbeddingConfig.BATCH_SIZE}\")\n",
        "    print(f\"  Workers: {EmbeddingConfig.MAX_WORKERS}\")\n",
        "    print(f\"  Model: {EmbeddingConfig.EMBEDDING_MODEL}\")\n",
        "    print(f\"  Dimensions: {EmbeddingConfig.OUTPUT_DIMENSION}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Process in batches with parallel workers\n",
        "    total_batches = (len(df_to_process) + EmbeddingConfig.BATCH_SIZE - 1) // EmbeddingConfig.BATCH_SIZE\n",
        "\n",
        "    with tqdm(total=len(df_to_process), desc=\"Generating embeddings\") as pbar:\n",
        "        for batch_num in range(total_batches):\n",
        "            start_idx = batch_num * EmbeddingConfig.BATCH_SIZE\n",
        "            end_idx = min(start_idx + EmbeddingConfig.BATCH_SIZE, len(df_to_process))\n",
        "            batch_df = df_to_process.iloc[start_idx:end_idx]\n",
        "\n",
        "            # Process batch in parallel\n",
        "            with ThreadPoolExecutor(max_workers=EmbeddingConfig.MAX_WORKERS) as executor:\n",
        "                futures = {\n",
        "                    executor.submit(process_single_movie_embedding, row): idx\n",
        "                    for idx, row in batch_df.iterrows()\n",
        "                }\n",
        "\n",
        "                for future in as_completed(futures):\n",
        "                    result = future.result()\n",
        "                    results.append(result)\n",
        "\n",
        "                    if result['error']:\n",
        "                        errors.append(result['movieId'])\n",
        "\n",
        "                    pbar.update(1)\n",
        "\n",
        "            # Save progress after each batch\n",
        "            if len(results) % EmbeddingConfig.SAVE_INTERVAL == 0 or end_idx == len(df_to_process):\n",
        "                df_progress = pd.DataFrame(results)\n",
        "                df_progress = df_progress[df_progress['error'].isna()]  # Only save successful\n",
        "                save_embeddings_progress(df_progress, EmbeddingConfig.PROGRESS_FILE)\n",
        "\n",
        "    # Final save\n",
        "    df_results = pd.DataFrame(results)\n",
        "    df_results = df_results[df_results['error'].isna()]\n",
        "    save_embeddings_progress(df_results, EmbeddingConfig.OUTPUT_FILE)\n",
        "\n",
        "    # Summary statistics\n",
        "    elapsed = time.time() - start_time\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Embedding Generation Complete!\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"  Total movies: {len(df)}\")\n",
        "    print(f\"  Newly processed: {len(df_to_process)}\")\n",
        "    print(f\"  Total with embeddings: {len(df_results)}\")\n",
        "    print(f\"  Successful: {len(df_results) - len(errors)}\")\n",
        "    print(f\"  Errors: {len(errors)}\")\n",
        "    if len(df_to_process) > 0:\n",
        "        print(f\"  Time elapsed: {elapsed/60:.1f} minutes\")\n",
        "        print(f\"  Average time per movie: {elapsed/len(df_to_process):.2f} seconds\")\n",
        "        print(f\"  Throughput: {len(df_to_process)/elapsed*60:.1f} movies/minute\")\n",
        "    print(f\"\\n  Output file: {EmbeddingConfig.OUTPUT_FILE}\")\n",
        "\n",
        "    if errors:\n",
        "        print(f\"  Error log: {EmbeddingConfig.ERROR_LOG}\")\n",
        "        print(f\"  Error rate: {len(errors)/len(df_results)*100:.1f}%\")\n",
        "\n",
        "    return df_results\n",
        "\n",
        "print(\"‚úÖ Parallel embedding processing functions defined\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpLYoc4Tvf5w",
        "outputId": "b7a06e00-9580-4d12-85ab-39aab7acd5c0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Parallel embedding processing functions defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate embeddings for all movies\n",
        "df_with_embeddings = process_movie_embeddings(df_movies_with_summaries)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "09fa716cddcd41a98206fc5f6746e70c",
            "a2a5a64934864c288dffaa44481400bd",
            "9952520d5984455d9a18f5f9d5122081",
            "656fdefc45964fc9b8feba3406f34f26",
            "a3faf751f93e44459bb577442ea95be0",
            "d53aeb6351394a64a0a63096bf60475c",
            "28087cdaa1a24f13b891499fb49ddaa2",
            "fafe29b2c6024bd594357bc1f570a026",
            "b20aca13248342a08a730db689a14159",
            "8099f1c8778b4bd4acc686743925c0a7",
            "c53b78cef5144e15bc849f7d803db115"
          ]
        },
        "id": "9AS3s1vQvk_z",
        "outputId": "4374d99f-911b-4866-e2c0-64ceff79a1b2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÇ Found existing progress file: embedding_progress.csv\n",
            "  ‚úÖ Loaded 500 successful embeddings\n",
            "  üìù Remaining to process: 9242\n",
            "\n",
            "============================================================\n",
            "Starting PARALLEL embedding generation\n",
            "  Total movies: 9742\n",
            "  Already processed: 500\n",
            "  Movies to process: 9242\n",
            "  Batch size: 100\n",
            "  Workers: 50\n",
            "  Model: gemini-embedding-001\n",
            "  Dimensions: 1536\n",
            "============================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating embeddings:   0%|          | 0/9242 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09fa716cddcd41a98206fc5f6746e70c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  üíæ Progress saved: embedding_progress.csv (600 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (700 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (800 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (900 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (1000 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (1100 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (1200 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (1300 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (1400 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (1500 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (1600 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (1700 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (1800 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (1900 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (2000 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (2100 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (2200 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (2300 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (2400 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (2500 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (2600 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (2700 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (2800 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (2900 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (3000 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (3100 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (3200 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (3300 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (3400 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (3500 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (3600 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (3700 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (3800 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (3900 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (4000 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (4100 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (4200 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (4300 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (4400 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (4500 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (4600 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (4700 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (4800 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (4900 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (5000 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (5100 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (5200 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (5300 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (5400 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (5500 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (5600 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (5700 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (5800 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (5900 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (6000 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (6100 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (6200 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (6300 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (6400 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (6500 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (6600 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (6700 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (6800 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (6900 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (7000 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (7100 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (7200 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (7300 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (7400 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (7500 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (7600 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (7700 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (7800 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (7900 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (8000 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (8100 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (8200 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (8300 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (8400 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (8500 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (8600 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (8700 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (8800 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (8900 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (9000 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (9100 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (9200 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (9300 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (9400 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (9500 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (9600 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (9700 movies)\n",
            "  üíæ Progress saved: embedding_progress.csv (9742 movies)\n",
            "  üíæ Progress saved: embeddings.csv (9742 movies)\n",
            "\n",
            "============================================================\n",
            "Embedding Generation Complete!\n",
            "============================================================\n",
            "  Total movies: 9742\n",
            "  Newly processed: 9242\n",
            "  Total with embeddings: 9742\n",
            "  Successful: 9742\n",
            "  Errors: 0\n",
            "  Time elapsed: 31.1 minutes\n",
            "  Average time per movie: 0.20 seconds\n",
            "  Throughput: 297.5 movies/minute\n",
            "\n",
            "  Output file: embeddings.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüìä Embedding Generation Results:\\n\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Check dimensions\n",
        "if len(df_with_embeddings) > 0:\n",
        "    sample_embedding = df_with_embeddings.iloc[0]['embedding']\n",
        "    print(f\"Embedding dimension: {len(sample_embedding)}\")\n",
        "    print(f\"Expected dimension: {EmbeddingConfig.OUTPUT_DIMENSION}\")\n",
        "    print(f\"‚úì Dimension check: {'PASS' if len(sample_embedding) == EmbeddingConfig.OUTPUT_DIMENSION else 'FAIL'}\")\n",
        "\n",
        "    print(f\"\\nTotal movies with embeddings: {len(df_with_embeddings)}\")\n",
        "    print(f\"\\nSample embedding (first 10 values):\")\n",
        "    print(f\"  Movie: {df_with_embeddings.iloc[0]['movieId']}\")\n",
        "    print(f\"  Vector: {sample_embedding[:10]}...\")\n",
        "\n",
        "    # Check file size\n",
        "    output_path = Path(EmbeddingConfig.OUTPUT_FILE)\n",
        "    if output_path.exists():\n",
        "        file_size_mb = output_path.stat().st_size / (1024 * 1024)\n",
        "        print(f\"\\nOutput file size: {file_size_mb:.1f} MB\")\n",
        "\n",
        "    print(\"\\n‚úÖ Embeddings ready for import!\")\n",
        "else:\n",
        "    print(\"‚ùå No embeddings generated\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXSMlN83vlwi",
        "outputId": "c1af7626-093d-43c3-875c-a8f01f75e6a7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Embedding Generation Results:\n",
            "\n",
            "============================================================\n",
            "Embedding dimension: 1536\n",
            "Expected dimension: 1536\n",
            "‚úì Dimension check: PASS\n",
            "\n",
            "Total movies with embeddings: 9742\n",
            "\n",
            "Sample embedding (first 10 values):\n",
            "  Movie: 38\n",
            "  Vector: [0.00706884590908885, -0.005984412506222725, -0.036130573600530624, -0.059679530560970306, -0.027341127395629883, 0.010750919580459595, -0.008083591237664223, 0.0008646799251437187, 0.0018894285894930363, -0.006449270527809858]...\n",
            "\n",
            "Output file size: 321.2 MB\n",
            "\n",
            "‚úÖ Embeddings ready for import!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "movie_summary_generator.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "09fa716cddcd41a98206fc5f6746e70c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a2a5a64934864c288dffaa44481400bd",
              "IPY_MODEL_9952520d5984455d9a18f5f9d5122081",
              "IPY_MODEL_656fdefc45964fc9b8feba3406f34f26"
            ],
            "layout": "IPY_MODEL_a3faf751f93e44459bb577442ea95be0"
          }
        },
        "a2a5a64934864c288dffaa44481400bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d53aeb6351394a64a0a63096bf60475c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_28087cdaa1a24f13b891499fb49ddaa2",
            "value": "Generating‚Äáembeddings:‚Äá100%"
          }
        },
        "9952520d5984455d9a18f5f9d5122081": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fafe29b2c6024bd594357bc1f570a026",
            "max": 9242,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b20aca13248342a08a730db689a14159",
            "value": 9242
          }
        },
        "656fdefc45964fc9b8feba3406f34f26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8099f1c8778b4bd4acc686743925c0a7",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c53b78cef5144e15bc849f7d803db115",
            "value": "‚Äá9242/9242‚Äá[30:41&lt;00:00,‚Äá‚Äá5.38it/s]"
          }
        },
        "a3faf751f93e44459bb577442ea95be0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d53aeb6351394a64a0a63096bf60475c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28087cdaa1a24f13b891499fb49ddaa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fafe29b2c6024bd594357bc1f570a026": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b20aca13248342a08a730db689a14159": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8099f1c8778b4bd4acc686743925c0a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c53b78cef5144e15bc849f7d803db115": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}